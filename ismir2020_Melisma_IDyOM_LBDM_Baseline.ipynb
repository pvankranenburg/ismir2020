{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MTCFeatures import MTCFeatureLoader\n",
    "from fractions import Fraction\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "epsilon = 0.0001\n",
    "import pickle\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFirstSequencedNote(seq):\n",
    "    for ix, val in enumerate(seq['features']['nextisrest']):\n",
    "        if ix==0: continue #skip first\n",
    "        if not val: #there is no rest following\n",
    "            return ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the melody sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_mtc = MTCFeatureLoader('ismir2020_seqs_mtc.jsonl.gz').sequences()\n",
    "seqs_mtc = list(seqs_mtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_chor = MTCFeatureLoader('ismir2020_seqs_chor.jsonl.gz').sequences()\n",
    "seqs_chor = list(seqs_chor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_essen = MTCFeatureLoader('ismir2020_seqs_essen.jsonl.gz').sequences()\n",
    "seqs_essen = list(seqs_essen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate notelist as input for melisma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2notelist(seq):\n",
    "    duration_frac = seq['features']['duration_frac']\n",
    "    restduration_frac = seq['features']['restduration_frac']\n",
    "    onsettick = seq['features']['onsettick']\n",
    "    midipitch = seq['features']['midipitch']\n",
    "    #find out length of onset tick\n",
    "    #find index of first note without rest following\n",
    "    ix = findFirstSequencedNote(seq)\n",
    "    tick_duration = Fraction(duration_frac[ix]) / ( Fraction(onsettick[ix+1]) - Fraction(onsettick[ix]) )\n",
    "    onset = 0\n",
    "    notes = []\n",
    "    for ix, val in enumerate(duration_frac):\n",
    "        dur_ticks = int(Fraction(val) / tick_duration)\n",
    "        if restduration_frac[ix] is not None:\n",
    "            rest_ticks = int(Fraction(restduration_frac[ix]) / tick_duration)\n",
    "            #print(ix, onset, \"rest\")\n",
    "        else:\n",
    "            rest_ticks = 0\n",
    "        offset = onset + dur_ticks\n",
    "        notes.append( (onset, offset, midipitch[ix]) )\n",
    "        onset = onset + dur_ticks + rest_ticks\n",
    "    #check whether computed onsets are same as provided onsets\n",
    "    for ix, val in enumerate(notes):\n",
    "        if notes[ix][0] != onsettick[ix]:\n",
    "            print(f\"{seq['id']}: Difference in onset at position {ix}, onsettick: {onsettick[ix]}\")\n",
    "            break\n",
    "    #multiply by 100\n",
    "    notes = [ (onset*100, offset*100, midipitch) for onset, offset, midipitch in notes ]\n",
    "    return notes\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2notelistBeatduration(seq):\n",
    "    # use beat = 1 second (=1000ms)\n",
    "    beatfraction = seq['features']['beatfraction']\n",
    "    duration_frac = seq['features']['duration_frac']\n",
    "    restduration_frac = seq['features']['restduration_frac']\n",
    "    midipitch = seq['features']['midipitch']\n",
    "    beatlength = [ Fraction(dur) / Fraction(bf) for dur, bf in zip(duration_frac, beatfraction)]\n",
    "    restdurationbeat_frac = [ Fraction(rd) / bl if rd is not None else None for rd, bl in zip(restduration_frac, beatlength) ]\n",
    "    notes = []\n",
    "    onset = 0\n",
    "    for ix, bf in enumerate(beatfraction):\n",
    "        notedur = Fraction(1000) * ( Fraction(bf) )\n",
    "        if restdurationbeat_frac[ix] is not None:\n",
    "            totaldur = Fraction(1000) * ( Fraction(bf) + restdurationbeat_frac[ix] )\n",
    "        else:\n",
    "            totaldur = notedur\n",
    "        notes.append( (onset, onset+int(notedur), midipitch[ix] ) )\n",
    "        onset += int(totaldur)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeNoteList(notelist, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for ix, note in enumerate(notelist):\n",
    "            f.write(f'Note {note[0]} {note[1]} {note[2]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the notelist files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    for seq in seqs_mtc:\n",
    "        writeNoteList( seq2notelistBeatduration(seq), f\"ismir2020_melisma/notefiles/mtcfsinst/{seq['id']}.notes\" )\n",
    "\n",
    "    for seq in seqs_essen:\n",
    "        writeNoteList( seq2notelistBeatduration(seq), f\"ismir2020_melisma/notefiles/essen/{seq['id']}.notes\" )\n",
    "\n",
    "    for seq in seqs_chor:\n",
    "        writeNoteList( seq2notelistBeatduration(seq), f\"ismir2020_melisma/notefiles/chor/{seq['id']}.notes\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in command shell: invoke melisma meter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert phrase ends in .nb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertPhraseEnd(path, seq):\n",
    "    songid = seq['id']\n",
    "    prhaseend = seq['features']['phrase_end']\n",
    "    with open(os.path.join(path,songid+'.nb'), 'r') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    with open(os.path.join(path,songid+'.nb'), 'w') as f:\n",
    "        ix = 0\n",
    "        for line in lines:\n",
    "            f.write(line)\n",
    "            f.write('\\n')\n",
    "            if line[:4] == 'Note':\n",
    "                if prhaseend[ix]:\n",
    "                    f.write(\"|\\n\")\n",
    "                ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'ismir2020_melisma/nbfiles/mtcfsinst'\n",
    "for seq in seqs_mtc:\n",
    "    try:\n",
    "        insertPhraseEnd(path, seq)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'ismir2020_melisma/nbfiles/essen'\n",
    "for seq in seqs_essen:\n",
    "    try:\n",
    "        insertPhraseEnd(path, seq)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'ismir2020_melisma/nbfiles/chor'\n",
    "for seq in seqs_chor:\n",
    "    try:\n",
    "        insertPhraseEnd(path, seq)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read groupers phrase boundaries as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in seqs_mtc:\n",
    "    with open(f\"ismir2020_melisma/boundaries/mtcfsinst/{seq['id']}.bd\", 'r') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    grouper_boundaries = []\n",
    "    for pair in zip(lines, lines[1:]):\n",
    "        if pair[0][:4] == 'Note':\n",
    "            if pair[1][:6] == 'Phrase':\n",
    "                grouper_boundaries.append(True)\n",
    "            else:\n",
    "                grouper_boundaries.append(False)\n",
    "    #check length\n",
    "    if len(grouper_boundaries) != len(seq['features']['scaledegree']):\n",
    "        print(f'{seq[id]}: unequal lengths')\n",
    "    seq['features'] = {}\n",
    "    seq['features']['grouper'] = grouper_boundaries\n",
    "\n",
    "MTCFeatureLoader.writeJSON('ismir2020_melisma/mtcfsinst_grouper.jsonl.gz', seqs_mtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in seqs_essen:\n",
    "    with open(f\"ismir2020_melisma/boundaries/essen/{seq['id']}.bd\", 'r') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    grouper_boundaries = []\n",
    "    for pair in zip(lines, lines[1:]):\n",
    "        if pair[0][:4] == 'Note':\n",
    "            if pair[1][:6] == 'Phrase':\n",
    "                grouper_boundaries.append(True)\n",
    "            else:\n",
    "                grouper_boundaries.append(False)\n",
    "    #check length\n",
    "    if len(grouper_boundaries) != len(seq['features']['scaledegree']):\n",
    "        print(f'{seq[id]}: unequal lengths')\n",
    "    seq['features'] = {}\n",
    "    seq['features']['grouper'] = grouper_boundaries\n",
    "\n",
    "MTCFeatureLoader.writeJSON('ismir2020_melisma/essen_grouper.jsonl.gz', seqs_essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in seqs_chor:\n",
    "    with open(f\"ismir2020_melisma/boundaries/chor/{seq['id']}.bd\", 'r') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    grouper_boundaries = []\n",
    "    for pair in zip(lines, lines[1:]):\n",
    "        if pair[0][:4] == 'Note':\n",
    "            if pair[1][:6] == 'Phrase':\n",
    "                grouper_boundaries.append(True)\n",
    "            else:\n",
    "                grouper_boundaries.append(False)\n",
    "    #check length\n",
    "    if len(grouper_boundaries) != len(seq['features']['scaledegree']):\n",
    "        print(f'{seq[id]}: unequal lengths')\n",
    "    seq['features'] = {}\n",
    "    seq['features']['grouper'] = grouper_boundaries\n",
    "\n",
    "MTCFeatureLoader.writeJSON('ismir2020_melisma/chor_grouper.jsonl.gz', seqs_chor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDyOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add IDyOM information content from IDyOM to the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the sequences and make dict\n",
    "seqs_mtc = MTCFeatureLoader('ismir2020_seqs_mtc.jsonl.gz').sequences()\n",
    "seqs_mtc = list(seqs_mtc)\n",
    "\n",
    "#have a dict\n",
    "seqs_mtc_dict = { seq['id'] : seq for seq in seqs_mtc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_chor = MTCFeatureLoader('ismir2020_seqs_chor.jsonl.gz').sequences()\n",
    "seqs_chor = list(seqs_chor)\n",
    "\n",
    "#have a dict\n",
    "seqs_chor_dict = { seq['id'] : seq for seq in seqs_chor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_essen = MTCFeatureLoader('ismir2020_seqs_essen.jsonl.gz').sequences()\n",
    "seqs_essen = list(seqs_essen)\n",
    "\n",
    "#have a dict\n",
    "seqs_essen_dict = { seq['id'] : seq for seq in seqs_essen}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select some columns from IDyOM's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceIdyomDF(df):\n",
    "    #only retain columns with ID, phrase and information.content\n",
    "    df = df.loc[:,['dataset.id','melody.id','note.id','melody.name','phrase','information.content']]\n",
    "    df.rename(\n",
    "        columns={\n",
    "            'dataset.id': 'dataset_id',\n",
    "            'melody.id': 'melody_id',\n",
    "            'note.id': 'note_id',\n",
    "            'melody.name': 'melody_name',\n",
    "            'information.content': 'information_content'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    #make meaningful index\n",
    "    df['id'] = df.apply(\n",
    "        lambda row: '-'.join(\n",
    "            [\n",
    "                str(row.melody_name),\n",
    "                str(row.note_id)\n",
    "            ]\n",
    "        ),\n",
    "        axis = 1\n",
    "    )\n",
    "    df.set_index(['id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idyom_out_mtc = pd.read_csv(\n",
    "    '/Users/krane108/Documents/Eigenwerk/Projects/ScaleDegrees/IDyOM/3-cpitch_bioi_deltast-cpitch_bioi_deltast-nil-nil-melody-nil-10-both+-nil-t-nil-c-nil-t-t-x-3.csv',\n",
    "    sep = ' '\n",
    ")\n",
    "idyom_out_essen = pd.read_csv(\n",
    "    '/Users/krane108/Documents/Eigenwerk/Projects/ScaleDegrees/IDyOM/4-cpitch_bioi_deltast-cpitch_bioi_deltast-nil-nil-melody-nil-10-both+-nil-t-nil-c-nil-t-t-x-3.csv',\n",
    "    sep = ' '\n",
    ")\n",
    "idyom_out_chor  = pd.read_csv(\n",
    "    '/Users/krane108/Documents/Eigenwerk/Projects/ScaleDegrees/IDyOM/2-cpitch_bioi_deltast-cpitch_bioi_deltast-nil-nil-melody-nil-10-both+-nil-t-nil-c-nil-t-t-x-3.csv',\n",
    "    sep = ' '\n",
    ")\n",
    "\n",
    "idyom_out_mtc = reduceIdyomDF(idyom_out_mtc)\n",
    "idyom_out_chor = reduceIdyomDF(idyom_out_chor)\n",
    "idyom_out_essen = reduceIdyomDF(idyom_out_essen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write seqences to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icfeats_mtc = defaultdict(list)\n",
    "\n",
    "for row in idyom_out_mtc.values:\n",
    "    icfeats_mtc[row[3]].append(row[5])\n",
    "    \n",
    "for songid in icfeats_mtc.keys():\n",
    "    #check lengths\n",
    "    if len(seqs_mtc_dict[songid]['features']['scaledegree']) != len(icfeats_mtc[songid]):\n",
    "        print(\"Unequal lengths: \" + songid)\n",
    "    seqs_mtc_dict[songid]['features'] = {}\n",
    "    seqs_mtc_dict[songid]['features']['informationcontent'] = icfeats_mtc[songid]\n",
    "    \n",
    "MTCFeatureLoader.writeJSON('ismir2020_melisma_IDyOM_sel/mtcfsinst_vocal_meter_after1850_1pertf_informationcontent.jsonl.gz', seqs_mtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icfeats_essen = defaultdict(list)\n",
    "\n",
    "for row in idyom_out_essen.values:\n",
    "    icfeats_essen[row[3]].append(row[5])\n",
    "\n",
    "for songid in icfeats_essen.keys():\n",
    "    #check lengths\n",
    "    if len(essen_seqs_dict[songid]['features']['scaledegree']) != len(icfeats_essen[songid]):\n",
    "        print(\"Unequal lengths: \" + songid)\n",
    "    essen_seqs_dict[songid]['features'] = {}\n",
    "    essen_seqs_dict[songid]['features']['informationcontent'] = icfeats_essen[songid]\n",
    "\n",
    "MTCFeatureLoader.writeJSON('ismir2020_melisma_IDyOM_sel/essen_erk_meter_informationcontent.jsonl.gz', essen_seqs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icfeats_chor = defaultdict(list)\n",
    "\n",
    "for row in idyom_out_chor.values:\n",
    "    icfeats_chor[row[3]].append(row[5])\n",
    "\n",
    "for songid in icfeats_chor.keys():\n",
    "    #check lengths\n",
    "    if len(chor_seqs_dict[songid]['features']['scaledegree']) != len(icfeats_chor[songid]):\n",
    "        print(\"Unequal lengths: \" + songid)\n",
    "    chor_seqs_dict[songid]['features'] = {}\n",
    "    chor_seqs_dict[songid]['features']['informationcontent'] = icfeats_chor[songid]\n",
    "\n",
    "MTCFeatureLoader.writeJSON('ismir2020_melisma_IDyOM_sel/chor_meter_informationcontent.jsonl.gz', chor_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the rest baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the sequences\n",
    "\n",
    "seqs_mtc = MTCFeatureLoader('ismir2020_seqs_mtc.jsonl.gz').sequences()\n",
    "seqs_mtc = list(seqs_mtc)\n",
    "\n",
    "#selection for ismir2020\n",
    "with open('ismir2020_songids_mtc.txt', 'r') as f:\n",
    "    songids_mtc = [line.rstrip() for line in f.readlines()]\n",
    "seqs_mtc = [seq for seq in seqs_mtc if seq['id'] in songids_mtc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_essen = MTCFeatureLoader('ismir2020_seqs_essen.jsonl.gz').sequences()\n",
    "seqs_essen = list(seqs_essen)\n",
    "\n",
    "#selection for ismir2020\n",
    "with open('ismir2020_songids_essen.txt', 'r') as f:\n",
    "    songids_essen = [line.rstrip() for line in f.readlines()]\n",
    "seqs_essen = [seq for seq in seqs_essen if seq['id'] in songids_essen]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_chor = MTCFeatureLoader('ismir2020_seqs_chor.jsonl.gz').sequences()\n",
    "seqs_chor = list(seqs_chor)\n",
    "\n",
    "#selection for ismir2020\n",
    "with open('ismir2020_songids_chor.txt', 'r') as f:\n",
    "    songids_chor = [line.rstrip() for line in f.readlines()]\n",
    "seqs_chor = [seq for seq in seqs_chor if seq['id'] in songids_chor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1323, 1632, 370)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs_mtc),len(seqs_essen),len(seqs_chor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(TP, FP, FN):\n",
    "    precision = TP / (TP+FP)\n",
    "    recall = TP / (TP+FN)\n",
    "    F1 = 2*precision*recall / (precision+recall)\n",
    "    print(f\"Pr: {precision}\")\n",
    "    print(f\"Rc: {recall}\")\n",
    "    print(f\"F1: {F1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count True Positives, False Positives, and False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restPredictions(corpus):\n",
    "    TP,FP,FN = 0,0,0\n",
    "    for seq in corpus:\n",
    "        feats = list(zip(seq['features']['nextisrest'],seq['features']['phrase_end']))\n",
    "        for rest,phraseend in feats[:-1]:\n",
    "            if rest and phraseend: TP += 1\n",
    "            if rest and not phraseend: FP += 1\n",
    "            if not rest and phraseend: FN +=1\n",
    "    return TP, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr: 0.9213483146067416\n",
      "Rc: 0.2557051736357194\n",
      "F1: 0.4003106623765672\n"
     ]
    }
   ],
   "source": [
    "evaluate(*restPredictions(seqs_mtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr: 0.9535529972211195\n",
      "Rc: 0.31182656108009865\n",
      "F1: 0.4699667384073567\n"
     ]
    }
   ],
   "source": [
    "evaluate(*restPredictions(seqs_essen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr: 0.9942857142857143\n",
      "Rc: 0.09124278972207656\n",
      "F1: 0.16714697406340057\n"
     ]
    }
   ],
   "source": [
    "evaluate(*restPredictions(seqs_chor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute always baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def always(pos, neg):\n",
    "    TP = pos\n",
    "    FP = neg\n",
    "    FN = 0\n",
    "    evaluate(TP, FP, FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr: 0.0994782118177972\n",
      "Rc: 1.0\n",
      "F1: 0.18095531270842952\n"
     ]
    }
   ],
   "source": [
    "#MTC\n",
    "always(7054, 63856)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr: 0.10974028749305487\n",
      "Rc: 1.0\n",
      "F1: 0.1977765225428777\n"
     ]
    }
   ],
   "source": [
    "#ESSEN\n",
    "always(7703, 62490)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr: 0.10983757631609262\n",
      "Rc: 1.0\n",
      "F1: 0.19793450620167108\n"
     ]
    }
   ],
   "source": [
    "#CHOR\n",
    "always(1907, 15455)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute LBDM boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the sequences and make dict\n",
    "with open('ismir2020_songids_mtc.txt', 'r') as f:\n",
    "    songids_mtc = [line.rstrip() for line in f.readlines()]\n",
    "\n",
    "vocal_seqs = MTCFeatureLoader('ismir2020_seqs_mtc.jsonl.gz').sequences()\n",
    "vocal_seqs = [seq for seq in vocal_seqs if seq['id'] in songids_mtc]\n",
    "\n",
    "#have a dict\n",
    "vocal_seqs_dict = { seq['id'] : seq for seq in vocal_seqs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ismir2020_songids_essen.txt', 'r') as f:\n",
    "    songids_essen = [line.rstrip() for line in f.readlines()]\n",
    "\n",
    "essen_seqs = MTCFeatureLoader('ismir2020_seqs_essen.jsonl.gz').sequences()\n",
    "essen_seqs = [seq for seq in essen_seqs if seq['id'] in songids_essen]\n",
    "\n",
    "#have a dict\n",
    "essen_seqs_dict = { seq['id'] : seq for seq in essen_seqs}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ismir2020_songids_chor.txt', 'r') as f:\n",
    "    songids_chor = [line.rstrip() for line in f.readlines()]\n",
    "\n",
    "chor_seqs = MTCFeatureLoader('ismir2020_seqs_chor.jsonl.gz').sequences()\n",
    "chor_seqs = [seq for seq in chor_seqs if seq['id'] in songids_chor]\n",
    "\n",
    "#have a dict\n",
    "chor_seqs_dict = { seq['id'] : seq for seq in chor_seqs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLBDMBoundaries(corpus, percentage):\n",
    "    #first collect all values\n",
    "    allLBDM = [seq['features']['lbdm_boundarystrength'] for seq in corpus]\n",
    "    allLBDM = list(chain.from_iterable(allLBDM))\n",
    "    allLBDM = [val if val is not None else 0 for val in allLBDM]\n",
    "    allLBDM = sorted(allLBDM, reverse=True)\n",
    "    ix = int(len(allLBDM) * percentage)\n",
    "    threshold = allLBDM[ix]\n",
    "    #collect boundaries and groundtruth\n",
    "    y = []\n",
    "    y_pred = []\n",
    "    for seq in corpus:\n",
    "        for bd in seq['features']['lbdm_boundarystrength'][:-1]:\n",
    "            if bd is not None:\n",
    "                y_pred.append(1 if bd>=threshold else 0)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "        for bd in seq['features']['endOfPhrase'][:-1]:\n",
    "            if bd:\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n",
    "    return y, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(corpus):\n",
    "    res = []\n",
    "    for percentage in range(1,100):\n",
    "        if percentage%10==0: print(percentage)\n",
    "        p = float(percentage) / 100.0\n",
    "        y, y_pred = computeLBDMBoundaries(corpus, p)\n",
    "        f1 = f1_score(y,y_pred)\n",
    "        res.append((p, f1))\n",
    "    res = sorted(res, key = lambda x: x[1], reverse=True)\n",
    "    print (res[0])\n",
    "    y, y_pred = computeLBDMBoundaries(corpus, res[0][0])\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "(0.08, 0.5488272267361644)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96     66501\n",
      "           1       0.60      0.51      0.55      7055\n",
      "\n",
      "    accuracy                           0.92     73556\n",
      "   macro avg       0.77      0.74      0.75     73556\n",
      "weighted avg       0.91      0.92      0.92     73556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search(vocal_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "(0.08, 0.5262698931763681)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     65754\n",
      "           1       0.60      0.47      0.53      7703\n",
      "\n",
      "    accuracy                           0.91     73457\n",
      "   macro avg       0.77      0.72      0.74     73457\n",
      "weighted avg       0.90      0.91      0.91     73457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search(essen_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "(0.09, 0.4504201680672269)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     16195\n",
      "           1       0.48      0.42      0.45      1907\n",
      "\n",
      "    accuracy                           0.89     18102\n",
      "   macro avg       0.71      0.68      0.70     18102\n",
      "weighted avg       0.89      0.89      0.89     18102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search(chor_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp",
   "language": "python",
   "name": "tmp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
