{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run -i 'ismir2020_make_datasets.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MTCFeatures import MTCFeatureLoader\n",
    "import music21 as m21\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the Melody sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MTCFeatures 1.1: If a melody ends with a melisma, the melismastate of the last note is 'in' instead of 'end'.\n",
    "This function does repair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixFinalMelismastate(seq_iter):\n",
    "    for seq in seq_iter:\n",
    "        seq['features']['melismastate'][-1] = 'end'\n",
    "        yield seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MTCFeatures 1.1: 234 songs have type 'vocal' but no lyrics. So we need another filter for vocal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocalFilter(seq_iter):\n",
    "    for seq in seq_iter:\n",
    "        if 'melismastate' in seq['features'].keys():\n",
    "            yield seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to add grouper predictions, and IDyOM information content to the sequences as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addGrouper(seq_iter, grouperfilename):\n",
    "    grouper_seqs = list(MTCFeatureLoader(grouperfilename).sequences())\n",
    "    grouper_seqs_dict = {seq['id'] : seq for seq in grouper_seqs}\n",
    "    for seq in seq_iter:\n",
    "        if seq['id'] in grouper_seqs_dict.keys():\n",
    "            seq['features']['grouper'] = grouper_seqs_dict[seq['id']]['features']['grouper']\n",
    "            if len(grouper_seqs_dict[seq['id']]['features']['grouper']) != len(seq['features']['scaledegree']):\n",
    "                print (\"Different length in grouper: \", seq['id'])\n",
    "        yield seq\n",
    "        \n",
    "def addInformationContent(seq_iter, icfilename):\n",
    "    ic_seqs = list(MTCFeatureLoader(icfilename).sequences())\n",
    "    ic_seqs_dict = {seq['id'] : seq for seq in ic_seqs}\n",
    "    for seq in seq_iter:\n",
    "        if seq['id'] in ic_seqs_dict.keys():\n",
    "            seq['features']['informationcontent'] = ic_seqs_dict[seq['id']]['features']['informationcontent']\n",
    "            if len(ic_seqs_dict[seq['id']]['features']['informationcontent']) != len(seq['features']['scaledegree']):\n",
    "                print (\"Different length in grouper: \", seq['id'])\n",
    "        yield seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 7300 7400 "
     ]
    }
   ],
   "source": [
    "readFSFromDisk = True\n",
    "\n",
    "if readFSFromDisk:\n",
    "    vocal_seqs = MTCFeatureLoader('ismir2020_seqs_mtc.jsonl.gz').sequences()\n",
    "    vocal_seqs = list(vocal_seqs)\n",
    "else:\n",
    "    fsinst_dl = MTCFeatureLoader('MTC-FS-INST-2.0')\n",
    "    vocal_seqs = fsinst_dl.applyFilters([\n",
    "            {'mfilter':'freemeter', 'invert':True},\n",
    "            {'mfilter':(\"afteryear\",1850)} ]\n",
    "    )\n",
    "    vocal_seqs = vocalFilter(vocal_seqs)\n",
    "    vocal_seqs = fixFinalMelismastate(vocal_seqs)\n",
    "    vocal_seqs = extractFeatures(vocal_seqs, vocalfeatures=True)\n",
    "    vocal_seqs = addGrouper(vocal_seqs, 'ismir2020_melisma_IDyOM_sel/mtcfsinst_vocal_meter_after1850_1pertf_grouper.jsonl.gz')\n",
    "    vocal_seqs = list(vocal_seqs)\n",
    "    MTCFeatureLoader.writeJSON('ismir2020_seqs_mtc.jsonl.gz', vocal_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the right informationcontent (trained on the target set - either full or the 1pertf selection)\n",
    "#vocal_seqs = addInformationContent(vocal_seqs, 'ismir2020_melisma_IDyOM_sel/mtcfsinst_vocal_meter_after1850_informationcontent.jsonl.gz')\n",
    "vocal_seqs = addInformationContent(vocal_seqs, 'ismir2020_melisma_IDyOM_sel/mtcfsinst_vocal_meter_after1850_1pertf_informationcontent.jsonl.gz')\n",
    "vocal_seqs = list(vocal_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 7300 7400 "
     ]
    }
   ],
   "source": [
    "readESSENFromDisk = True\n",
    "\n",
    "if readESSENFromDisk:\n",
    "    essen_seqs = MTCFeatureLoader('ismir2020_seqs_essen.jsonl.gz').sequences()\n",
    "    essen_seqs = list(essen_seqs)\n",
    "else:\n",
    "    essen_dl = MTCFeatureLoader('ESSEN')\n",
    "    essen_seqs = essen_dl.sequences()\n",
    "    essen_seqs = [seq for seq in essen_seqs if seq['freemeter']==False]\n",
    "    essen_seqs = extractFeatures(essen_seqs, vocalfeatures=False)\n",
    "    essen_seqs = addGrouper(essen_seqs, 'ismir2020_melisma_IDyOM_sel/essen_erk_meter_grouper.jsonl.gz')\n",
    "    essen_seqs = list(essen_seqs)\n",
    "    MTCFeatureLoader.writeJSON('ismir2020_seqs_essen.jsonl.gz', essen_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the right informationcontent (trained on the target set - either full or Erk)\n",
    "#essen_seqs = addInformationContent(essen_seqs, 'ismir2020_melisma_IDyOM_sel/essen_meter_informationcontent.jsonl.gz')\n",
    "essen_seqs = addInformationContent(essen_seqs, 'ismir2020_melisma_IDyOM_sel/essen_erk_meter_informationcontent.jsonl.gz')\n",
    "essen_seqs = list(essen_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 200 300 "
     ]
    }
   ],
   "source": [
    "readCHORFromDisk = True\n",
    "\n",
    "if readCHORFromDisk:\n",
    "    chor_seqs = MTCFeatureLoader('ismir2020_seqs_chor.jsonl.gz').sequences()\n",
    "    chor_seqs = list(chor_seqs)\n",
    "else:\n",
    "    chor_dl = MTCFeatureLoader('chorale_sequences.jsonl.gz')\n",
    "    chor_seqs = chor_dl.sequences()\n",
    "    chor_seqs = [seq for seq in chor_seqs if seq['freemeter']==False]\n",
    "    chor_seqs = extractFeatures(chor_seqs, vocalfeatures=False)\n",
    "    chor_seqs = addGrouper(chor_seqs, 'ismir2020_melisma_IDyOM_sel/chor_meter_grouper.jsonl.gz')\n",
    "    chor_seqs = addInformationContent(chor_seqs, 'ismir2020_melisma_IDyOM_sel/chor_meter_informationcontent.jsonl.gz')\n",
    "    chor_seqs = list(chor_seqs)\n",
    "    MTCFeatureLoader.writeJSON('ismir2020_seqs_chor.jsonl.gz', chor_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection of subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do selection of songs here to prevent storing 5-grams for the full data sets, which results in very large files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MTC\n",
    "with open('ismir2020_songids_mtc.txt', 'r') as f:\n",
    "    songids_mtc = [line.rstrip() for line in f.readlines()]\n",
    "vocal_seqs = [seq for seq in vocal_seqs if seq['id'] in songids_mtc]\n",
    "\n",
    "MTCFeatureLoader.writeJSON('ismir2020_seqs_mtc_sel.jsonl.gz', vocal_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESSEN\n",
    "with open('ismir2020_songids_essen.txt', 'r') as f:\n",
    "    songids_essen = [line.rstrip() for line in f.readlines()]\n",
    "essen_seqs = [seq for seq in essen_seqs if seq['id'] in songids_essen]\n",
    "\n",
    "MTCFeatureLoader.writeJSON('ismir2020_seqs_essen_sel.jsonl.gz', essen_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHOR\n",
    "with open('ismir2020_songids_chor.txt', 'r') as f:\n",
    "    songids_chor = [line.rstrip() for line in f.readlines()]\n",
    "chor_seqs = [seq for seq in chor_seqs if seq['id'] in songids_chor]\n",
    "\n",
    "MTCFeatureLoader.writeJSON('ismir2020_seqs_chor_sel.jsonl.gz', chor_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the 5-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 "
     ]
    }
   ],
   "source": [
    "readPGramsFromDisk = True\n",
    "\n",
    "if readPGramsFromDisk:\n",
    "    pgrams = pd.read_pickle(\"ismir2020_pgrams_mtc_sel.pkl\")\n",
    "    arfftype = pickle.load( open( \"ismir2020_arfftype_mtc_sel.pkl\", \"rb\" ) )\n",
    "else:\n",
    "    pgrams, arfftype = extractPgramsFromCorpus(vocal_seqs, pgram_type='note')\n",
    "    pgrams.to_pickle(\"ismir2020_pgrams_mtc_sel.pkl\")\n",
    "    pickle.dump(arfftype, open('ismir2020_arfftype_mtc_sel.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 "
     ]
    }
   ],
   "source": [
    "readESSENPGramsFromDisk = True\n",
    "\n",
    "if readESSENPGramsFromDisk:\n",
    "    essen_pgrams = pd.read_pickle(\"ismir2020_pgrams_essen_sel.pkl\")\n",
    "    essen_arfftype = pickle.load( open( \"ismir2020_arfftype_essen_sel.pkl\", \"rb\" ) )\n",
    "else:\n",
    "    essen_pgrams, essen_arfftype = extractPgramsFromCorpus(essen_seqs, pgram_type='note')\n",
    "    essen_pgrams.to_pickle(\"ismir2020_pgrams_essen_sel.pkl\")\n",
    "    pickle.dump(essen_arfftype, open(\"ismir2020_arfftype_essen_sel.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 "
     ]
    }
   ],
   "source": [
    "readCHORPGramsFromDisk = True\n",
    "\n",
    "if readCHORPGramsFromDisk:\n",
    "    chor_pgrams = pd.read_pickle(\"ismir2020_pgrams_chor_sel.pkl\")\n",
    "    chor_arfftype = pickle.load( open( \"ismir2020_arfftype_chor.pkl\", \"rb\" ) )\n",
    "else:\n",
    "    chor_pgrams, chor_arfftype = extractPgramsFromCorpus(chor_seqs, pgram_type='note')\n",
    "    chor_pgrams.to_pickle(\"ismir2020_pgrams_chor_sel.pkl\")\n",
    "    pickle.dump(chor_arfftype, open(\"ismir2020_arfftype_chor_sel.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp",
   "language": "python",
   "name": "tmp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
